# Data Cleaning, Integration, and EDA Project

##  Overview
This project involves analyzing, cleaning, merging, and deriving insights from real-world datasets provided for a Data Analytics/ML internship evaluation. The workflow spans raw data preparation, integration, exploratory data analysis, and stakeholder-ready visual reporting.

---

## Tools Used
- Python 3.x
- Pandas, NumPy
- Seaborn, Matplotlib
- NLTK / Regex (for basic NLP tagging)
- Jupyter Notebook / VS Code

---

## Tasks Breakdown

### Task 1: Column Analysis & Cleaning
- Performed column-wise analysis (data types, uniqueness, nulls).
- Cleaned inconsistencies and formatted numeric/categorical data.
- Identified top 5 critical columns and visualized key insights.
- Extracted tags from text fields using basic NLP techniques.

### Task 2: Data Integration
- Identified primary key(s) for merging datasets.
- Cleaned both datasets (formatting, translation, deduplication).
- Merged datasets using left/inner join and justified approach.

### Task 3: Exploratory Data Analysis
- Visualized trends (e.g., failed components vs. actual hours/cost).
- Root cause analysis of failure/fix conditions.
- Shared key findings and business impact for stakeholders.

---

## Deliverables
- `task1_cleaned_data.csv` — Cleaned dataset with tags
- `task2_merged_data.csv` — Final merged dataset
- `task1_report.pdf` — Summary (column analysis, visualizations)
- `task2_3_summary.pdf` — Cleaning, merging, and EDA report
- `analysis_scripts/` — Python scripts used in analysis